{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 'monGPT\n",
    "\n",
    "This program builds plausible gen 8 ou teams using minGPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from showdown_dataset import StartingPokemonDataset, PokemonDataset, RandomizeTeamWrapper, InputTeamWrapper, GPTTeamWrapper\n",
    "from team_generator import predict_starting_pokemon, decode_pokemon_team, tokenize_pokemon_team\n",
    "\n",
    "from mongpt.model import GPT\n",
    "from mongpt.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading replays: 100%|██████████| 1250/1250 [00:00<00:00, 6443.35it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# load the dataset\n",
    "dataset = StartingPokemonDataset('dataset/gen9ou/replays', num_starting_pokemon=1)\n",
    "\n",
    "# randomly split the dataset into an 80/20 train/test split\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "\n",
    "train_dataset = RandomizeTeamWrapper(train_dataset, num_starting_pokemon=1)\n",
    "train_dataset = GPTTeamWrapper(train_dataset, num_starting_pokemon=1)\n",
    "\n",
    "test_dataset = GPTTeamWrapper(test_dataset, num_starting_pokemon=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.72M\n"
     ]
    }
   ],
   "source": [
    "# create the minGPT model\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-mini'\n",
    "model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "model_config.block_size = train_dataset.get_block_size()\n",
    "model = GPT(model_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create the trainer\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 2000\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# create an evaluation function\n",
    "\n",
    "def eval_model(model, dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    num_correct = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(trainer.device)\n",
    "        y = y.to(trainer.device)\n",
    "        truth = y[:, -1:]\n",
    "        preds = model.generate(x, 1, no_duplicates=False, select_from_team=True)[:, -1:]\n",
    "        num_correct += (preds == truth).sum()\n",
    "    return num_correct / len(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 5.53282\n",
      "iter_dt 12.00ms; iter 100: train loss 3.10730\n",
      "epoch 1: train accuracy 0.43; test accuracy 0.33\n",
      "iter_dt 13.00ms; iter 200: train loss 2.64355\n",
      "iter_dt 14.00ms; iter 300: train loss 2.05980\n",
      "epoch 2: train accuracy 0.51; test accuracy 0.36\n",
      "iter_dt 13.00ms; iter 400: train loss 1.87896\n",
      "iter_dt 13.00ms; iter 500: train loss 1.67000\n",
      "epoch 3: train accuracy 0.59; test accuracy 0.35\n",
      "iter_dt 12.00ms; iter 600: train loss 1.43283\n",
      "epoch 4: train accuracy 0.64; test accuracy 0.35\n",
      "iter_dt 14.00ms; iter 700: train loss 1.37142\n",
      "iter_dt 12.00ms; iter 800: train loss 1.08136\n",
      "epoch 5: train accuracy 0.69; test accuracy 0.40\n",
      "iter_dt 13.00ms; iter 900: train loss 1.15502\n",
      "iter_dt 13.00ms; iter 1000: train loss 0.93650\n",
      "epoch 6: train accuracy 0.72; test accuracy 0.34\n",
      "iter_dt 15.00ms; iter 1100: train loss 0.89358\n",
      "epoch 7: train accuracy 0.77; test accuracy 0.35\n",
      "iter_dt 13.00ms; iter 1200: train loss 0.66273\n",
      "iter_dt 13.00ms; iter 1300: train loss 0.82238\n",
      "epoch 8: train accuracy 0.80; test accuracy 0.35\n",
      "iter_dt 13.00ms; iter 1400: train loss 0.74147\n",
      "iter_dt 14.00ms; iter 1500: train loss 0.52062\n",
      "epoch 9: train accuracy 0.82; test accuracy 0.35\n",
      "iter_dt 13.00ms; iter 1600: train loss 0.62767\n",
      "iter_dt 14.00ms; iter 1700: train loss 0.32111\n",
      "epoch 10: train accuracy 0.85; test accuracy 0.34\n",
      "iter_dt 12.00ms; iter 1800: train loss 0.59381\n",
      "epoch 11: train accuracy 0.86; test accuracy 0.32\n",
      "iter_dt 13.00ms; iter 1900: train loss 0.65449\n"
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "\n",
    "\n",
    "def epoch_end_callback(trainer): # this requires our custom `monGPT\n",
    "    train_accuracy = eval_model(trainer.model, train_dataset)\n",
    "    test_accuracy = eval_model(trainer.model, test_dataset)\n",
    "    print(f\"epoch {trainer.epoch_num}: train accuracy {train_accuracy:.2f}; test accuracy {test_accuracy:.2f}\")\n",
    "\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "trainer.set_callback('on_epoch_end', epoch_end_callback)\n",
    "\n",
    "trainer.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, 'monGPT_starter.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "Now we can calculate the accuracy of the model on the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# x, y = next(iter(dataloader))\n",
    "#\n",
    "# x = x.to(trainer.device)\n",
    "#\n",
    "# model.generate(x, 1, no_duplicates=False, select_from_team=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "    x = x.to(trainer.device)\n",
    "    y = y.to(trainer.device)\n",
    "    #print('x,y = ', x, y)\n",
    "    truth = y[:, -1:]\n",
    "    preds = model.generate(x, 1, no_duplicates=False, select_from_team=True)[:, -1:]\n",
    "    #print('Truth = ', truth)\n",
    "    #print('Preds = ', preds)\n",
    "    num_correct += (preds == truth).sum()\n",
    "\n",
    "print(f\"Accuracy: {num_correct / len(test_dataset):.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference\n",
    "\n",
    "Now, lets see how well the model can predict the starting pokemon of a team"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Greninja', 'Tyranitar', 'Haxorus', 'Cinderace', 'Zoroark-Hisui', 'Samurott'] ['Dragonite', 'Ceruledge', 'Abomasnow', 'Gyarados', 'Garchomp', 'Mimikyu']\n"
     ]
    }
   ],
   "source": [
    "x, _ = test_dataset[0]\n",
    "team1 = x[:6]\n",
    "team2 = x[6:12]\n",
    "team1 = decode_pokemon_team(team1)\n",
    "team2 = decode_pokemon_team(team2)\n",
    "print(team1, team2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cinderace']\n"
     ]
    }
   ],
   "source": [
    "print(predict_starting_pokemon(team1, team2, 1, model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
